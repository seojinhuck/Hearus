# -*- coding: utf-8 -*-
"""Roberta.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G-33C1yXdPXISm-KzITt2wz-uLfYbuA9
"""



import torch
from transformers import RobertaModel, RobertaConfig

def prune_model(model, pruning_rate=0.2):

    # 모델의 모든 선형 계층을 순회하며 가중치를 Pruning함
    for name, module in model.named_modules():
        if isinstance(module, torch.nn.Linear):
            # Pruning할 가중치 결정: 가중치 절대값의 하위 pruning_rate 비율 제거
            threshold = torch.quantile(torch.abs(module.weight.data), pruning_rate)
            mask = torch.abs(module.weight.data) > threshold
            module.weight.data *= mask.float()  # Pruning 적용

# RoBERTa 모델 인스턴스 생성
roberta_model = RobertaModel(RobertaConfig())

# Pruning을 적용할 가중치 비율 설정 (예: 20%)
pruning_rate = 0.2

# Pruning 함수를 호출하여 모델에 적용
prune_model(roberta_model, pruning_rate)

